#Importing Necessary Libraries 
import pandas as pd
from pandas import read_csv
import numpy as np
import matplotlib.pyplot as plt


# Defining the filename
training_dataset_path = 'Training.csv'
testing_dataset_path = 'Testing.csv'

# Reading the CSV file into a pandas 
training_data = pd.read_csv(training_dataset_path)
testing_data = pd.read_csv(testing_dataset_path)

# Displaying the first few rows of the data
training_data.head()






#Dataset rows and columns 
training_data.shape


# Displaying information about the data
training_data.info()



training_data.dtypes


#display last 5 data in the dataset
training_data.tail()


# Generating descriptive statistics of the data
training_data.describe()



# Checking for missing values 
training_data.isnull().sum()


import matplotlib.pyplot as plt
import seaborn as sns

# Disease Distribution in Training Dataset
disease_counts_visualization = training_data['prognosis'].value_counts()

# Disease Distribution Visualization
plt.figure(figsize=(10, 8))
sns.countplot(y='prognosis', data=training_data, order = training_data['prognosis'].value_counts().index)
plt.title('Disease Distribution in Training Dataset')
plt.xlabel('Count')
plt.ylabel('Disease')
plt.show()


# Symptom Frequency Analysis
symptom_columns_visualization = training_data.columns[:-2]  # Exclude 'prognosis' and 'Unnamed: 133'
symptom_frequencies_visualization = training_data[symptom_columns_visualization].sum().sort_values(ascending=False)

# Symptom Frequency Visualization (Top 20)
plt.figure(figsize=(10, 8))
sns.barplot(x=symptom_frequencies_visualization.head(20).values, y=symptom_frequencies_visualization.head(20).index)
plt.title('Top 20 Most Frequent Symptoms in the Training Dataset')
plt.xlabel('Frequency')
plt.ylabel('Symptoms')
plt.show()


# Corrected disease encoding dictionary with lowercase keys
disease_encoding = {
    'fungal infection': 0, 'allergy': 1, 'gerd': 2, 'chronic cholestasis': 3, 'drug reaction': 4,
    'peptic ulcer diseae': 5, 'aids': 6, 'diabetes': 7, 'gastroenteritis': 8, 'bronchial asthma': 9, 'hypertension': 10,
    'migraine': 11, 'cervical spondylosis': 12, 'paralysis (brain hemorrhage)': 13, 'jaundice': 14, 'malaria': 15,
    'chicken pox': 16, 'dengue': 17, 'typhoid': 18, 'hepatitis a': 19, 'hepatitis b': 20, 'hepatitis c': 21,
    'hepatitis d': 22, 'hepatitis e': 23, 'alcoholic hepatitis': 24, 'tuberculosis': 25, 'common cold': 26,
    'pneumonia': 27, 'dimorphic hemmorhoids(piles)': 28, 'heart attack': 29, 'varicose veins': 30, 'hypothyroidism': 31,
    'hyperthyroidism': 32, 'hypoglycemia': 33, 'osteoarthristis': 34, 'arthritis': 35,
    '(vertigo) paroymsal  positional vertigo': 36, 'acne': 37, 'urinary tract infection': 38, 'psoriasis': 39,
    'impetigo': 40
}

# Apply the corrected encoding to training data
training_data['prognosis'] = training_data['prognosis'].replace(disease_encoding)

# Apply the same corrected encoding to testing data
testing_data['prognosis'] = testing_data['prognosis'].replace(disease_encoding)





training_data.dtypes





# Creating a list of column names from the dataset
disease_list = training_data.columns.tolist()

# Printing the list of column names
print(disease_list)


from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split

# Drop the Unnamed: 133 column from the training dataset if present
if 'Unnamed: 133' in training_data.columns:
    X_train = training_data.drop(columns=['prognosis', 'Unnamed: 133'])
else:
    X_train = training_data.drop(columns=['prognosis'])

y_train = training_data['prognosis']
X_test = testing_data.drop(columns=['prognosis'])
y_test = testing_data['prognosis']

# Impute missing values if there are any
imputer = SimpleImputer(strategy='median')
X_train_imputed = imputer.fit_transform(X_train)
X_test_imputed = imputer.transform(X_test)



 X_train.shape


 X_train.head()


X_train.dtypes


from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Initialize the Random Forest Classifier
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the classifier 
rf_classifier.fit(X_train_imputed, y_train)

y_pred = rf_classifier.predict(X_test_imputed)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy*100:.2f}%")






from sklearn.model_selection import GridSearchCV

# Define the parameter grid
param_grid = {
    'n_estimators': [100, 200],  
    'max_depth': [None, 20],  
    'min_samples_split': [2, 10],  
    'min_samples_leaf': [1, 4]  
}

# Initialize the GridSearchCV object
grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='accuracy')

# Fit the grid search to the data
grid_search.fit(X_train_imputed, y_train)

# Print the best parameters and the best score
print(f"Best Parameters: {grid_search.best_params_}")
print(f"Best Score: {grid_search.best_score_ * 100:.2f}%")



# Using the best parameters from the grid search to create a new Random Forest model
final_rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_leaf=1, min_samples_split=2, random_state=42)

# Training the model on the full training dataset
final_rf_classifier.fit(X_train_imputed, y_train)

# Predicting on the test dataset
final_predictions = final_rf_classifier.predict(X_test_imputed)

# Evaluating the final model's performance
final_accuracy = accuracy_score(y_test, final_predictions)
print(f"Final Model Accuracy on Test Set: {final_accuracy*100:.2f}%")






from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# Compute confusion matrix
cm = confusion_matrix(y_test, final_predictions)

# Create a ConfusionMatrixDisplay instance
cmd = ConfusionMatrixDisplay(cm, display_labels=final_rf_classifier.classes_)

# Plot the confusion matrix
fig, ax = plt.subplots(figsize=(10, 10))
cmd.plot(ax=ax, xticks_rotation='vertical')

plt.title('Confusion Matrix Display')
plt.show()



# Get feature importances
importances = final_rf_classifier.feature_importances_

# Convert the feature importances to a Series
feature_importances = pd.Series(importances, index=X_train.columns)

# Plot the top 20 most important features
plt.figure(figsize=(10, 8))
feature_importances.nlargest(20).plot(kind='barh')
plt.title('Top 20 Most Important Features')
plt.show()



import joblib

# Save the model to disk
model_path = 'final_rf_classifier.pkl'
joblib.dump(final_rf_classifier, model_path)

print(f"Model saved to {model_path}")


loaded_classifier = joblib.load('final_rf_classifier.pkl')



# All Symptoms 
# Extracting only the symptoms columns
list_a = ['itching', 'skin_rash', 'nodal_skin_eruptions', 'continuous_sneezing', 'shivering', 'chills', 'joint_pain', 'stomach_pain', 'acidity', 'ulcers_on_tongue', 'muscle_wasting', 'vomiting', 'burning_micturition', 'spotting_ urination', 'fatigue', 'weight_gain', 'anxiety', 'cold_hands_and_feets', 'mood_swings', 'weight_loss', 'restlessness', 'lethargy', 'patches_in_throat', 'irregular_sugar_level', 'cough', 'high_fever', 'sunken_eyes', 'breathlessness', 'sweating', 'dehydration', 'indigestion', 'headache', 'yellowish_skin', 'dark_urine', 'nausea', 'loss_of_appetite', 'pain_behind_the_eyes', 'back_pain', 'constipation', 'abdominal_pain', 'diarrhoea', 'mild_fever', 'yellow_urine', 'yellowing_of_eyes', 'acute_liver_failure', 'fluid_overload', 'swelling_of_stomach', 'swelled_lymph_nodes', 'malaise', 'blurred_and_distorted_vision', 'phlegm', 'throat_irritation', 'redness_of_eyes', 'sinus_pressure', 'runny_nose', 'congestion', 'chest_pain', 'weakness_in_limbs', 'fast_heart_rate', 'pain_during_bowel_movements', 'pain_in_anal_region', 'bloody_stool', 'irritation_in_anus', 'neck_pain', 'dizziness', 'cramps', 'bruising', 'obesity', 'swollen_legs', 'swollen_blood_vessels', 'puffy_face_and_eyes', 'enlarged_thyroid', 'brittle_nails', 'swollen_extremeties', 'excessive_hunger', 'extra_marital_contacts', 'drying_and_tingling_lips', 'slurred_speech', 'knee_pain', 'hip_joint_pain', 'muscle_weakness', 'stiff_neck', 'swelling_joints', 'movement_stiffness', 'spinning_movements', 'loss_of_balance', 'unsteadiness', 'weakness_of_one_body_side', 'loss_of_smell', 'bladder_discomfort', 'foul_smell_of urine', 'continuous_feel_of_urine', 'passage_of_gases', 'internal_itching', 'toxic_look_(typhos)', 'depression', 'irritability', 'muscle_pain', 'altered_sensorium', 'red_spots_over_body', 'belly_pain', 'abnormal_menstruation', 'dischromic _patches', 'watering_from_eyes', 'increased_appetite', 'polyuria', 'family_history', 'mucoid_sputum', 'rusty_sputum', 'lack_of_concentration', 'visual_disturbances', 'receiving_blood_transfusion', 'receiving_unsterile_injections', 'coma', 'stomach_bleeding', 'distention_of_abdomen', 'history_of_alcohol_consumption', 'fluid_overload', 'blood_in_sputum', 'prominent_veins_on_calf', 'palpitations', 'painful_walking', 'pus_filled_pimples', 'blackheads', 'scurring', 'skin_peeling', 'silver_like_dusting', 'small_dents_in_nails', 'inflammatory_nails', 'blister', 'red_sore_around_nose', 'yellow_crust_ooze']

print(list_a)
print(len(list_a))



# Initialize a list to store symptom indicators (0 for absence, 1 for presence)
list_c = [0] * len(list_a)
print(list_c)


#Patient symptoms list
list_b = ['itching', 'lethargy', 'family_history', 'dizziness', 'headache']


# Convert matching symptoms to 1's in list_c
for i in range (0,len(list_a)):
    for j in list_b:
        if(j == list_a[i]):
            list_c[i] = 1
            


print(list_c)


data_to_predict = np.array(list_c)
print(data_to_predict.shape)


# Convert symptom_indicators into a 2D array
converted_data_to_predict = np.array(data_to_predict).reshape(1,-1)
print(converted_data_to_predict.shape)


# making prediction
predicted_result = loaded_classifier.predict(converted_data_to_predict)
print(predicted_result)






description_data = pd.read_csv('treatment_datasets/description.csv')
description_data.head()


diets_data = pd.read_csv('treatment_datasets/diets.csv')
diets_data.head()


medication_data = pd.read_csv('treatment_datasets/medications.csv')
medication_data.head()


precautions_data = pd.read_csv('treatment_datasets/precautions_df.csv')
precautions_data.head()


workout_data = pd.read_csv('treatment_datasets/workout_df.csv')
workout_data.head()


# Merge datasets on the Disease column
complete_data = pd.merge(description_data, diets_data, on='Disease', how='inner')
complete_data = pd.merge(complete_data, medication_data, on='Disease', how='inner')
complete_data = pd.merge(complete_data, precautions_data, on='Disease', how='inner')
complete_data = pd.merge(complete_data, workout_data, on='Disease', how='inner')



complete_data.head()
#save csv
complete_data.to_csv('treatment_datasets/complete_treatment_data.csv', index=False)






import pandas as pd

# Load the dataset
data_path = 'treatment_datasets/complete_treatment_data.csv'
data = pd.read_csv(data_path)

# Display the first few rows of the dataset and some summary statistics
data.head()


data.describe(include='all')


data.info()


# Check for missing values
data.isnull().sum()


# Remove unnecessary columns
data_cleaned = data.drop(columns=['Unnamed: 0_x', 'Unnamed: 0.1', 'Unnamed: 0_y', 'workout'])

# Handle missing values in Precaution_3 and Precaution_4 by filling them with 'No specific precaution'
data_cleaned['Precaution_3'] = data_cleaned['Precaution_3'].fillna('No specific precaution')
data_cleaned['Precaution_4'] = data_cleaned['Precaution_4'].fillna('No specific precaution')

# Convert string representations of lists in Diet and Medication columns to actual lists
import ast  # Importing ast to safely evaluate strings containing Python expressions

data_cleaned['Diet'] = data_cleaned['Diet'].apply(ast.literal_eval)
data_cleaned['Medication'] = data_cleaned['Medication'].apply(ast.literal_eval)

# Display the cleaned data
data_cleaned.head()



data_cleaned.info()
data_cleaned.to_csv('treatment_datasets/Disease_treatment.csv', index=False)



import matplotlib.pyplot as plt
import seaborn as sns

# Set the aesthetic style of the plots
sns.set(style="whitegrid")

# Prepare data for visualization
disease_counts = data_cleaned['Disease'].value_counts()

# Visualization 1: Distribution of Diseases
plt.figure(figsize=(10, 8))
sns.barplot(y=disease_counts.index, x=disease_counts.values, palette='viridis')
plt.title('Distribution of Diseases in the Dataset')
plt.xlabel('Number of Entries')
plt.ylabel('Disease')
plt.show()





# Visualization 2: Top 5 Common Diets
diet_list = [item for sublist in data_cleaned['Diet'].tolist() for item in sublist]
diet_series = pd.Series(diet_list)
top_diets = diet_series.value_counts().head(5)

plt.figure(figsize=(8, 6))
sns.barplot(y=top_diets.index, x=top_diets.values, palette='coolwarm')
plt.title('Top 5 Common Diets Recommended')
plt.xlabel('Frequency')
plt.ylabel('Diet')
plt.show()




# Visualization 3: Top 5 Common Medications
medication_list = [item for sublist in data_cleaned['Medication'].tolist() for item in sublist]
medication_series = pd.Series(medication_list)
top_medications = medication_series.value_counts().head(5)

plt.figure(figsize=(8, 6))
sns.barplot(y=top_medications.index, x=top_medications.values, palette='magma')
plt.title('Top 5 Common Medications Recommended')
plt.xlabel('Frequency')
plt.ylabel('Medication')
plt.show()
